import asyncio
import uuid
import re
from pathlib import Path
from datetime import datetime

import typer
from rich.console import Console
from rich.markdown import Markdown
from rich.panel import Panel
from rich.prompt import Prompt

from utils import config
from context_engineering import memory
from tools.definitions import resolve_ticker
from agents.chat_agent import build_chat_agent
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from context_engineering.prompts import chat_agent_prompt

app = typer.Typer()
console = Console(width=100)

@app.callback()
def callback() -> None:
    """Intrepidq Equity Chat CLI"""
    from utils.cli_logger import logger
    logger.print_header()

#HELPER FUNCTIONS (Migrated from main.py)

def _normalize_content(content):
    """
    Normalize content to clean string, handling various formats from LLM responses.
    """
    if content is None:
        return "No content available"
    
    # Handle list of parts (common in Gemini responses)
    if isinstance(content, list):
        parts = []
        for part in content:
            if isinstance(part, dict):
                # Extract text from dict
                if "text" in part:
                    parts.append(str(part["text"]))
                elif "content" in part:
                    parts.append(str(part["content"]))
                else:
                    # Fallback: convert entire dict to string
                    parts.append(str(part))
            elif isinstance(part, str):
                parts.append(part)
            else:
                parts.append(str(part))
        
        text = "\n\n".join(parts)
    elif isinstance(content, dict):
        # Handle dict with text/content key
        if "text" in content:
            text = str(content["text"])
        elif "content" in content:
            text = str(content["content"])
        else:
            text = str(content)
    else:
        # Handle string or other types
        text = str(content)
    
    # Clean up the text
    text = _clean_text(text)
    
    return text


def _clean_text(text: str) -> str:
    """
    Clean and normalize text output.
    """
    # Remove control characters except newlines and tabs
    text = re.sub(r'[\x00-\x08\x0B-\x0C\x0E-\x1F\x7F]', '', text)
    
    # Normalize multiple newlines to max 2
    text = re.sub(r'\n{3,}', '\n\n', text)
    
    # Remove trailing whitespace from each line
    lines = [line.rstrip() for line in text.split('\n')]
    text = '\n'.join(lines)
    
    # Remove leading/trailing whitespace from entire text
    text = text.strip()
    
    return text


def _format_report(text: str, ticker: str) -> str:
    """Format the report with proper structure and headers."""
    # Add header if not present
    if not text.startswith('#') and ticker.upper() not in text[:100]:
        header = f"# {ticker} - Equity Analysis Report\n\n"
        text = header + text
    
    return text


def _save_report_to_file(text: str, ticker: str, session_id: str) -> Path:
    """Save report to a markdown file."""
    reports_dir = Path("reports")
    reports_dir.mkdir(exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{ticker}_{timestamp}.md"
    filepath = reports_dir / filename
    
    # Format the report with metadata
    formatted_text = f"""# {ticker} - Equity Analysis Report

**Generated:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}  
**Session ID:** {session_id}

---

{text}

---

*Report generated by IntrepidQ Equity Analysis System*
"""
    
    filepath.write_text(formatted_text, encoding='utf-8')
    return filepath

def _history_to_messages(history: list[dict]) -> list:
    """Convert internal dict history to LangChain Message objects.
    Always prepend the system prompt.
    """
    msgs: list = [SystemMessage(content=chat_agent_prompt)]
    for entry in history:
        if entry["role"] == "user":
            msgs.append(HumanMessage(content=entry["content"]))
        else:
            msgs.append(AIMessage(content=entry["content"]))
    return msgs

def _extract_response_content(content: str | list) -> str:
    """Extract text content from potential list structure."""
    if isinstance(content, list):
        text_parts = []
        for item in content:
            if isinstance(item, dict) and "text" in item:
                text_parts.append(item["text"])
        return "".join(text_parts)
    return str(content)

async def run_analysis_workflow(ticker: str, user_id: str = None, save_file: bool = True, auto_save: bool = False):
    """
    Async implementation of the analysis workflow using LangGraph.
    Features clean CLI logging with spinners and progress tracking.
    
    Args:
        ticker: Stock ticker symbol or company name
        user_id: User identifier for database storage
        save_file: Whether to save report to markdown file
        auto_save: If True, skip confirmation prompt and save to both file and database
    """
    from utils.cli_logger import logger
    
    user_id = user_id or config.DEFAULT_USER_ID
    
    # Resolve ticker if it's a company name
    original_input = ticker
    ticker = resolve_ticker(ticker)
    
    if ticker != original_input.upper():
        logger.log_success(f"Resolved '{original_input}' to ticker: {ticker}")

    # Initialize analysis tracking
    logger.start_analysis(ticker)

    session_id = f"analysis_{ticker}_{uuid.uuid4().hex[:6]}"

    try:
        from agents.graph import build_graph
        
        app = build_graph()
        
        # Config for the graph execution
        thread_id = str(uuid.uuid4())
        graph_config = {"configurable": {"thread_id": thread_id}}
        
        initial_state = {"ticker": ticker}
        
        # Run the graph until the first interruption or completion
        current_state = None
        
        # Initial run with phase tracking
        async for event in app.astream(initial_state, graph_config, stream_mode="values"):
            if "data_result" in event and "validation_result" not in event:
                logger.tracker.complete_phase("Data Collection")
            elif "validation_result" in event and "analysis_result" not in event:
                logger.tracker.complete_phase("Validation")
                if event.get("conflicts"):
                    logger.log_warning(f"{len(event['conflicts'])} Data Conflicts Detected!")

        # Check if we are interrupted
        snapshot = app.get_state(graph_config)
        
        if snapshot.next:
            # We are interrupted!
            logger.console.print("\n[bold red]ðŸ›‘ Workflow Paused: Human Review Required[/bold red]")
            
            state_values = snapshot.values
            conflicts = state_values.get("conflicts", [])
            data_result = state_values.get("data_result", {})
            financial_data = data_result.get("financial_data", {})
            
            if conflicts:
                logger.print_panel(f"Found {len(conflicts)} discrepancies between Yahoo Finance and Alpha Vantage.", title="Conflict Resolution", style="red")
                
                for conflict in conflicts:
                    metric = conflict['metric']
                    val_primary = conflict['primary_value']
                    val_ref = conflict['reference_value']
                    diff = conflict['diff_percent']
                    
                    logger.console.print(f"\n[bold]Conflict for '{metric}' (Diff: {diff:.2f}%):[/bold]")
                    logger.console.print(f"1. Yahoo Finance: [cyan]{val_primary}[/cyan]")
                    logger.console.print(f"2. Alpha Vantage: [magenta]{val_ref}[/magenta]")
                    
                    choice = typer.prompt("Select source to use (1/2)", type=int)
                    
                    if choice == 2:
                        logger.log_success(f"Updated {metric} to {val_ref}")
                        financial_data[metric] = val_ref
                    else:
                        logger.console.print(f"[dim]Keeping Yahoo Finance value: {val_primary}[/dim]")
                
                # Update state and resume
                data_result['financial_data'] = financial_data
                app.update_state(graph_config, {"data_result": data_result, "conflicts": []})
                
                # Continue execution
                async for event in app.astream(None, graph_config, stream_mode="values"):
                    if "analysis_result" in event and "final_report" not in event:
                        logger.tracker.complete_phase("Analysis")
                    elif "final_report" in event:
                        logger.tracker.complete_phase("Synthesis")
                        current_state = event

        else:
            current_state = snapshot.values
            # Mark remaining phases as complete if they were in state
            if current_state.get("analysis_result"):
                logger.tracker.complete_phase("Analysis")
            if current_state.get("final_report"):
                logger.tracker.complete_phase("Synthesis")

        # Final Output
        if current_state and "final_report" in current_state:
            final_report = current_state["final_report"]
            final_text = _format_report(final_report, ticker)

            # Show progress summary
            logger.print_summary()

            logger.print_panel(
                Markdown(final_text),
                title=f"ðŸ“Š {ticker} Analysis Report", 
                style="cyan"
            )

            # Human-in-the-loop: Ask user for save confirmation
            if not auto_save:
                save_choice = Prompt.ask(
                    "\n[bold yellow]ðŸ’¾ Save this report?[/bold yellow]\n"
                    "  [cyan]yes[/cyan] = Save to file AND database\n"
                    "  [cyan]no[/cyan] = Save to file only\n"
                    "  [cyan]cancel[/cyan] = Discard report",
                    choices=["yes", "no", "cancel"],
                    default="yes"
                )
                
                if save_choice == "cancel":
                    logger.log_warning("Report discarded by user.")
                    return
            else:
                save_choice = "yes"  # Auto-save mode saves to both
            
            # Save to file (always, unless cancelled)
            if save_file:
                filepath = _save_report_to_file(final_text, ticker, session_id)
                logger.log_success(f"Report saved to: {filepath}")
            
            # Save to database only if user chooses "yes"
            if save_choice == "yes":
                await memory.save_analysis_to_memory(
                    session_id=session_id,
                    user_id=user_id,
                    ticker=ticker,
                    report=final_text,
                )
                logger.log_success("Report saved to database.")
            else:
                console.print("[dim]Report saved to file only (not added to database).[/dim]")

    except Exception as e:
        logger.log_error(f"ERROR: {e}")
        import traceback
        traceback.print_exc()

@app.command()
def analyze(
    ticker: str,
    user_id: str = None,
    save_file: bool = typer.Option(True, "--save-file/--no-save-file", help="Save report to markdown file"),
    stream: bool = typer.Option(True, "--stream/--no-stream", help="Stream agent events in real-time"),
    auto_save: bool = typer.Option(False, "--auto-save", help="Skip confirmation prompt, save to both file and database")
):
    """
    Run multi-agent equity analysis on a stock ticker.
    
    After analysis, you will be prompted to save the report:
    - 'yes': Save to file AND database
    - 'no': Save to file only
    - 'cancel': Discard the report
    
    Use --auto-save to skip the prompt and save to both automatically.
    """
    asyncio.run(run_analysis_workflow(ticker, user_id, save_file, auto_save))


async def run_chat_loop(initial_ticker: str | None = None) -> None:
    """Main chat loop."""
    console.print(
        Panel.fit(
            "[bold cyan]ðŸ¤– Intrepidq Equity Chat[/bold cyan]\n\n"
            "Ask questions about your analyzed stocks.\n"
            "Type [bold yellow]analyze [ticker][/bold yellow] to start a new analysis.\n"
            "Type [bold yellow]/help[/bold yellow] for commands, "
            "[bold yellow]/exit[/bold yellow] to quit.",
            border_style="cyan",
        )
    )

    agent = build_chat_agent()
    chat_history: list[dict] = []

    # Optional initial ticker context
    if initial_ticker:
        initial_msg = f"Tell me about {initial_ticker} based on the analysis."
        console.print(f"\n[bold green]You:[/bold green] {initial_msg}")
        chat_history.append({"role": "user", "content": initial_msg})
        with console.status("[bold green]Thinking...[/bold green]"):
            msgs = _history_to_messages(chat_history)
            result = await agent.ainvoke({"messages": msgs})
            response = _extract_response_content(result["messages"][-1].content)
        chat_history.append({"role": "assistant", "content": response})
        console.print("\n[bold blue]AI:[/bold blue]")
        console.print(Markdown(response))

    while True:
        try:
            user_input = Prompt.ask("\n[bold green]You[/bold green]")
            user_input = user_input.strip()
            if not user_input:
                continue
            
            # Commands
            if user_input.lower() in ["/exit", "/quit", "exit", "quit"]:
                console.print("[yellow]Goodbye![/yellow]")
                break
            
            # Intercept 'analyze' command
            if user_input.lower().startswith("analyze "):
                _, t = user_input.split(maxsplit=1)
                await run_analysis_workflow(t)
                continue
                
            if user_input.lower() == "/help":
                console.print(
                    Panel(
                        "[bold]Commands:[/bold]\n"
                        "- analyze [ticker] : Start full analysis\n"
                        "- /tickers : List analyzed tickers\n"
                        "- /clear   : Clear conversation history\n"
                        "- /exit    : Exit chat",
                        title="Help",
                    )
                )
                continue
            if user_input.lower() == "/tickers":
                user_input = "List all analyzed tickers."
            if user_input.lower() == "/clear":
                chat_history = []
                console.print("[yellow]Conversation history cleared.[/yellow]")
                continue
                
            # Add user message
            chat_history.append({"role": "user", "content": user_input})
            with console.status("[bold green]Thinking...[/bold green]"):
                msgs = _history_to_messages(chat_history)
                result = await agent.ainvoke({"messages": msgs})
                response = _extract_response_content(result["messages"][-1].content)
            chat_history.append({"role": "assistant", "content": response})
            console.print("\n[bold blue]AI:[/bold blue]")
            console.print(Markdown(response))
        except KeyboardInterrupt:
            console.print("\n[yellow]Goodbye![/yellow]")
            break
        except Exception as e:
            console.print(f"\n[red]Error: {e}[/red]")

@app.command()
def start(ticker: str = typer.Argument(None)):
    """Start the chat interface."""
    asyncio.run(run_chat_loop(ticker))

if __name__ == "__main__":
    app()