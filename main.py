import asyncio
import uuid
import re
from pathlib import Path
from datetime import datetime

import typer
from rich.console import Console
from rich.markdown import Markdown
from rich.panel import Panel

import config
from context_engineering import memory
from agents import build_deep_agent


app = typer.Typer()
console = Console(width=100)  # Set consistent width for better formatting


# =============================================================================
# HELPER FUNCTIONS
# =============================================================================


def _normalize_content(content):
    """
    Normalize content to clean string, handling various formats from LLM responses.
    
    Handles:
    - List of parts (Gemini's format)
    - Dict with 'text' key
    - Plain strings
    - Objects with __str__ method
    """
    if content is None:
        return "No content available"
    
    # Handle list of parts (common in Gemini responses)
    if isinstance(content, list):
        parts = []
        for part in content:
            if isinstance(part, dict):
                # Extract text from dict
                if "text" in part:
                    parts.append(str(part["text"]))
                elif "content" in part:
                    parts.append(str(part["content"]))
                else:
                    # Fallback: convert entire dict to string
                    parts.append(str(part))
            elif isinstance(part, str):
                parts.append(part)
            else:
                parts.append(str(part))
        
        text = "\n\n".join(parts)
    elif isinstance(content, dict):
        # Handle dict with text/content key
        if "text" in content:
            text = str(content["text"])
        elif "content" in content:
            text = str(content["content"])
        else:
            text = str(content)
    else:
        # Handle string or other types
        text = str(content)
    
    # Clean up the text
    text = _clean_text(text)
    
    return text


def _clean_text(text: str) -> str:
    """
    Clean and normalize text output.
    
    - Remove excessive whitespace
    - Fix line breaks
    - Remove control characters
    - Normalize unicode
    """
    # Remove control characters except newlines and tabs
    text = re.sub(r'[\x00-\x08\x0B-\x0C\x0E-\x1F\x7F]', '', text)
    
    # Normalize multiple newlines to max 2
    text = re.sub(r'\n{3,}', '\n\n', text)
    
    # Remove trailing whitespace from each line
    lines = [line.rstrip() for line in text.split('\n')]
    text = '\n'.join(lines)
    
    # Remove leading/trailing whitespace from entire text
    text = text.strip()
    
    return text


def _format_report(text: str, ticker: str) -> str:
    """Format the report with proper structure and headers."""
    # Add header if not present
    if not text.startswith('#') and ticker.upper() not in text[:100]:
        header = f"# {ticker} - Equity Analysis Report\n\n"
        text = header + text
    
    return text


def _save_report_to_file(text: str, ticker: str, session_id: str) -> Path:
    """Save report to a markdown file."""
    reports_dir = Path("reports")
    reports_dir.mkdir(exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{ticker}_{timestamp}.md"
    filepath = reports_dir / filename
    
    # Format the report with metadata
    formatted_text = f"""# {ticker} - Equity Analysis Report

**Generated:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}  
**Session ID:** {session_id}

---

{text}

---

*Report generated by IntrepidQ Equity Analysis System*
"""
    
    filepath.write_text(formatted_text, encoding='utf-8')
    return filepath


# =============================================================================
# CLI COMMANDS
# =============================================================================


@app.command()
def analyze(
    ticker: str,
    user_id: str = None,
    save_file: bool = typer.Option(True, "--save-file/--no-save-file", help="Save report to markdown file"),
    stream: bool = typer.Option(True, "--stream/--no-stream", help="Stream agent events in real-time")
):
    """
    Run deep-agent-based analysis on a stock ticker.
    
    Args:
        ticker: Stock ticker symbol (e.g., TSLA, AAPL, MSFT)
        user_id: Optional user ID for tracking
        save_file: Whether to save the report to a file (default: True)
        stream: Whether to stream agent events in real-time (default: True)
    """
    user_id = user_id or config.DEFAULT_USER_ID
    ticker = ticker.upper().strip()

    console.print(f"\n[bold blue]üöÄ Deep Agent: Analyzing {ticker}...[/bold blue]\n")

    session_id = f"analysis_{ticker}_{uuid.uuid4().hex[:6]}"

    async def _run():
        try:
            agent = build_deep_agent()
            
            # In LangGraph, we pass messages to the agent
            # Format the system prompt and user message
            from context_engineering import deep_prompt
            from tools.validation import validate_data_completeness, format_validation_report
            from tools.definitions import get_deep_financials_tool
            
            # Pre-fetch financial data for validation
            console.print("[dim]üìä Fetching financial data...[/dim]")
            financial_result = get_deep_financials_tool.func(ticker)
            
            # Validate data completeness
            if financial_result.get("status") == "success":
                validation_result = validate_data_completeness(financial_result["data"])
                validation_report = format_validation_report(validation_result, ticker)
                
                # Display data quality summary
                console.print(f"[dim]Data Completeness: {validation_result['completeness_score']}% | Confidence: {validation_result['confidence_level']}[/dim]\n")
                
                # Inject validation context into prompt
                data_quality_context = f"\n\n**DATA QUALITY CONTEXT:**\n{validation_report}\n"
            else:
                data_quality_context = "\n\n**DATA QUALITY WARNING:** Failed to fetch financial data.\n"
                validation_report = ""
            
            # Get the system message content from the prompt template
            system_message_content = deep_prompt.messages[0].prompt.template + data_quality_context
            user_message = f"Perform a deep equity analysis for ticker {ticker}."

            if stream:
                console.print("[yellow]ü§ñ Agent starting analysis with real-time streaming...[/yellow]\n")
                
                # Use astream_events for real-time streaming
                final_text = ""
                tool_calls_made = []
                
                async for event in agent.astream_events(
                    {
                        "messages": [
                            {"role": "system", "content": system_message_content},
                            {"role": "user", "content": user_message}
                        ]
                    },
                    version="v1"
                ):
                    kind = event.get("event")
                    
                    # Tool call started
                    if kind == "on_tool_start":
                        tool_name = event.get("name", "unknown")
                        tool_input = event.get("data", {}).get("input", {})
                        
                        # Format tool input nicely
                        if isinstance(tool_input, dict):
                            input_str = ", ".join([f"{k}={v}" for k, v in tool_input.items()])
                        else:
                            input_str = str(tool_input)
                        
                        console.print(f"[cyan]üîß Calling tool:[/cyan] [bold]{tool_name}[/bold]")
                        if input_str and input_str != "{}":
                            console.print(f"   [dim]Input: {input_str}[/dim]")
                        tool_calls_made.append(tool_name)
                    
                    # Tool call completed
                    elif kind == "on_tool_end":
                        tool_name = event.get("name", "unknown")
                        console.print(f"[green]‚úì Completed:[/green] {tool_name}\n")
                    
                    # LLM thinking/responding
                    elif kind == "on_chat_model_start":
                        console.print("[magenta]üß† Agent thinking...[/magenta]")
                    
                    elif kind == "on_chat_model_stream":
                        # Stream LLM tokens (optional - can be verbose)
                        pass
                    
                    elif kind == "on_chat_model_end":
                        console.print("[green]‚úì Agent response complete[/green]\n")
                    
                    # Chain end - get final result
                    elif kind == "on_chain_end":
                        if event.get("data", {}).get("output"):
                            output = event["data"]["output"]
                            if isinstance(output, dict) and "messages" in output:
                                last_msg = output["messages"][-1]
                                final_text = _normalize_content(last_msg.content)
                
                # Summary of tools used
                if tool_calls_made:
                    console.print(f"[dim]üìä Tools used: {', '.join(set(tool_calls_made))}[/dim]\n")
            
            else:
                # Non-streaming mode (original behavior)
                console.print("[yellow]ü§ñ Deep agent planning and calling tools...[/yellow]\n")
                
                result = await agent.ainvoke({
                    "messages": [
                        {"role": "system", "content": system_message_content},
                        {"role": "user", "content": user_message}
                    ]
                })
                
                # Extract and normalize the final message
                if isinstance(result, dict) and "messages" in result:
                    last_msg = result["messages"][-1]
                    final_text = _normalize_content(last_msg.content)
                else:
                    final_text = _normalize_content(result)
            
            # Format the report
            final_text = _format_report(final_text, ticker)

            # Display the report with rich formatting
            console.print("\n")
            console.print(Panel(
                Markdown(final_text),
                title=f"[bold cyan]üìä {ticker} Analysis Report[/bold cyan]",
                border_style="cyan",
                padding=(1, 2)
            ))
            console.print("\n[bold green]‚úÖ Analysis Complete![/bold green]\n")

            # Save to database
            await memory.save_analysis_to_memory(
                session_id=session_id,
                user_id=user_id,
                ticker=ticker,
                report=final_text,
            )
            
            # Save to file if requested
            if save_file:
                filepath = _save_report_to_file(final_text, ticker, session_id)
                console.print(f"[dim]üíæ Report saved to: {filepath}[/dim]\n")

        except Exception as e:
            console.print(f"\n[bold red]‚ùå ERROR:[/bold red] {e}\n")
            import traceback
            traceback.print_exc()

    asyncio.run(_run())


@app.command()
def chat():
    """
    Minimal interactive mode: type 'analyze TICKER' or 'exit'.
    """
    console.print(
        "[bold green]üí¨ Chat Mode. Type 'analyze TICKER' or 'exit' to quit.[/bold green]\n"
    )

    while True:
        user_input = typer.prompt("You").strip()
        if user_input.lower() in ("exit", "quit"):
            console.print("[bold yellow]Goodbye![/bold yellow]")
            break

        if user_input.lower().startswith("analyze "):
            _, t = user_input.split(maxsplit=1)
            analyze(t)
        else:
            console.print("[yellow]Use 'analyze TICKER' or 'exit'.[/yellow]\n")


if __name__ == "__main__":
    app()
